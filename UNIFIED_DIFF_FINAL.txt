diff --git a/backend/app/services/amora_blocks_service.py b/backend/app/services/amora_blocks_service.py
index abc1234..def5678 100644
--- a/backend/app/services/amora_blocks_service.py
+++ b/backend/app/services/amora_blocks_service.py
@@ -234,6 +234,30 @@ class TopicEmotionDetector:
         return text.strip()
     
+    # Topic conflict policies: define allowed/denied topics per forced intent
+    TOPIC_POLICIES = {
+        'breakup_intimacy_loss': {
+            'allow': {'breakup_intimacy_loss', 'breakup_grief', 'breakup', 'heartbreak'},
+            'deny': {'unlovable', 'lust_vs_love', 'future_mismatch', 'different_futures'},
+        },
+        'breakup_grief': {
+            'allow': {'breakup_grief', 'heartbreak', 'breakup'},
+            'deny': {'unlovable'},
+        },
+    }
+    
+    # Explicit mention gates: topics that require explicit user statements
+    EXPLICIT_MENTION_GATES = {
+        'unlovable': ['unlovable', 'not lovable', 'no one will love me', 'worthless', 'feel unlovable', 'i am unlovable', 'im unlovable'],
+        'lust_vs_love': ['lust or love', 'attraction or love', 'just lust', 'sexual chemistry'],
+    }
+    
     # Comprehensive topic keywords
     TOPIC_KEYWORDS = {
         'heartbreak': ['heartbreak', 'heartbroken', 'broken heart', 'breakup', 'broke up', 'ended things', 'dumped', 'left me'],
@@ -395,7 +419,7 @@ class TopicEmotionDetector:
     @classmethod
     def detect_topics(cls, text: str, context_topics: Optional[List[str]] = None) -> List[str]:
         """
-        Detect topics from user message.
+        Detect topics from user message with priority-based routing and deterministic ordering.
         
         Process:
         1. Normalize text (lowercase, contractions, punctuation)
@@ -403,20 +427,60 @@ class TopicEmotionDetector:
         3. Check regular TOPIC_KEYWORDS
         4. Apply topic whitelist guardrails
+        5. Return topics in deterministic order (high-priority first)
         """
-        text_lower = text.lower()
+        # Normalize text for better matching
+        normalized_text = cls.normalize_text(text)
+        text_lower = normalized_text.lower()
         
         detected = set()
+        high_priority_detected = []
         
-        # Check topics
+        # Step 1: Check HIGH_PRIORITY topics with dual-signal requirement for breakup_intimacy_loss
+        # breakup_intimacy_loss requires BOTH breakup/ex signal AND intimacy signal
+        breakup_signals = ['ex', 'my ex', 'breakup', 'broke up', 'heartbroken', 'ended things', 'dumped', 'left me']
+        intimacy_signals = ['sex life', 'miss sex', 'miss our sex', 'intimacy', 'physical connection', 'chemistry', 'miss the way we', 'miss how we']
+        
+        is_breakup = any(signal in text_lower for signal in breakup_signals)
+        is_intimacy = any(signal in text_lower for signal in intimacy_signals)
+        
+        if is_breakup and is_intimacy:
+            high_priority_detected.append('breakup_intimacy_loss')
+            detected.add('breakup_intimacy_loss')
+            logger.info(f"[TopicDetection] HIGH PRIORITY topic detected: breakup_intimacy_loss (dual-signal: breakup={is_breakup}, intimacy={is_intimacy}, normalized text: {normalized_text[:100]})")
+        
+        # breakup_grief: check for heartbreak/grieving keywords
+        if any(kw in text_lower for kw in ['heartbroken', 'heartbreak', 'broken heart', 'grieving the breakup', 'grieving the loss', 'still grieving']):
+            high_priority_detected.append('breakup_grief')
+            detected.add('breakup_grief')
+            logger.info(f"[TopicDetection] HIGH PRIORITY topic detected: breakup_grief (normalized text: {normalized_text[:100]})")
+        
+        # Step 2: Check regular topics (always check, but high-priority takes precedence)
         for topic, keywords in cls.TOPIC_KEYWORDS.items():
+            # Skip if already detected as high-priority (avoid duplicates)
+            if topic not in high_priority_detected:
                 if any(keyword in text_lower for keyword in keywords):
                     detected.add(topic)
         
-        # Add context topics if still relevant
+        # Step 3: Add context topics if still relevant (and not conflicting)
         if context_topics:
             for topic in context_topics:
-                if topic in cls.TOPIC_KEYWORDS:
-                    keywords = cls.TOPIC_KEYWORDS[topic]
-                    if any(keyword in text_lower for keyword in keywords[:3]):
+                if topic in cls.TOPIC_KEYWORDS:
+                    keywords = cls.TOPIC_KEYWORDS[topic]
+                    if any(keyword in text_lower for keyword in keywords[:3]):
                         detected.add(topic)
         
-        return list(detected) if detected else ['general']
+        # Step 4: Apply guardrails - prevent wrong topics when specific intent detected
+        detected = cls._apply_topic_guardrails(detected, text_lower, high_priority_detected)
+        
+        # Step 5: Return in deterministic order (high-priority first, then sorted rest)
+        result = []
+        for t in high_priority_detected:
+            result.append(t)
+        for t in sorted(detected - set(high_priority_detected)):
+            result.append(t)
+        
+        if not result:
+            result = ['general']
+        
+        logger.info(f"[TopicDetection] Final topics (ordered): {result} (from normalized: {normalized_text[:100]})")
+        return result
+    
+    @classmethod
+    def _apply_topic_guardrails(cls, detected: set, text_lower: str, high_priority: List[str]) -> set:
+        """
+        Apply guardrails to prevent wrong topic blocks.
+        
+        Rules:
+        - If breakup_intimacy_loss detected, remove unrelated topics like 'unlovable', 'lust_vs_love' (unless explicitly stated)
+        - If breakup_grief detected, remove 'unlovable' unless user explicitly says they feel unlovable
+        - If breakup context, prioritize breakup-related topics
+        """
+        filtered = detected.copy()
+        
+        # If breakup_intimacy_loss is detected, remove conflicting topics
+        if 'breakup_intimacy_loss' in detected or 'breakup_intimacy_loss' in high_priority:
+            # Remove 'unlovable' unless explicitly stated
+            if 'unlovable' in filtered:
+                explicit_mentions = cls.EXPLICIT_MENTION_GATES.get('unlovable', [])
+                if not any(mention in text_lower for mention in explicit_mentions):
+                    filtered.discard('unlovable')
+                    logger.info("[TopicGuardrail] Removed 'unlovable' - not explicitly stated, breakup_intimacy_loss context")
+            
+            # Remove 'lust_vs_love' - not relevant when missing ex
+            if 'lust_vs_love' in filtered:
+                filtered.discard('lust_vs_love')
+                logger.info("[TopicGuardrail] Removed 'lust_vs_love' - not relevant for breakup_intimacy_loss")
+        
+        # If breakup_grief detected, remove 'unlovable' unless explicitly stated
+        if 'breakup_grief' in detected or 'heartbreak' in detected or 'breakup' in detected:
+            if 'unlovable' in filtered:
+                explicit_mentions = cls.EXPLICIT_MENTION_GATES.get('unlovable', [])
+                if not any(mention in text_lower for mention in explicit_mentions):
+                    filtered.discard('unlovable')
+                    logger.info("[TopicGuardrail] Removed 'unlovable' - not explicitly stated, breakup context")
+        
+        return filtered
     
     @classmethod
     def detect_emotions(cls, text: str, embedding: Optional[np.ndarray] = None) -> List[str]:
-        """Detect emotions from user message."""
-        text_lower = text.lower()
+        """Detect emotions from user message using normalized text."""
+        normalized_text = cls.normalize_text(text)
+        text_lower = normalized_text.lower()
         detected = {}
         
         for emotion, keywords in cls.EMOTION_KEYWORDS.items():
@@ -509,6 +509,7 @@ class BlockSelector:
     def select_block(
         self,
         block_type: str,
         question_embedding: np.ndarray,
         topics: List[str],
         emotions: List[str],
         stage: int,
         recent_block_ids: List[str],
-        min_similarity: float = 0.3
+        min_similarity: float = 0.3,
+        normalized_text: str = ""
     ) -> Optional[ResponseBlock]:
         """
         Select best matching block with anti-repetition.
@@ -596,6 +660,7 @@ class BlockSelector:
             # Score each candidate
             scored_blocks = []
             for block in candidates:
                 score = self._score_block(
                     block,
                     question_embedding,
                     topics,
                     emotions,
                     recent_block_ids
                 )
                 scored_blocks.append((block, score))
             
             # Sort by score descending
             scored_blocks.sort(key=lambda x: x[1], reverse=True)
             
+            # Apply topic policy filtering at block selection time
+            scored_blocks = self._apply_block_selection_filtering(
+                scored_blocks,
+                topics,
+                normalized_text=normalized_text
+            )
+            
             # Use weighted random selection from top-K candidates
             selected_block = self._weighted_random_choice(scored_blocks, min_similarity)
             
             if selected_block:
                 # Find the score for logging
                 selected_score = next((score for block, score in scored_blocks if block.id == selected_block.id), 0.0)
+                # Enhanced debug logging
+                forced_topic = topics[0] if topics else 'none'
+                logger.info(f"[BlockSelection] normalized_text={normalized_text[:100] if normalized_text else 'N/A'}")
+                logger.info(f"[BlockSelection] forced_topic={forced_topic}")
+                logger.info(f"[BlockSelection] selected_block_id={selected_block.id[:8]}")
+                logger.info(f"[BlockSelection] selected_block_topic={selected_block.topics}")
+                logger.info(f"[BlockSelection] similarity_score={selected_score:.3f}")
                 logger.info(f"[BlockSelection] Selected {block_type} block: id={selected_block.id[:8]}, score={selected_score:.3f}, topics={selected_block.topics}, text_preview={selected_block.text[:80]}...")
                 return selected_block
             
@@ -628,6 +693,60 @@ class BlockSelector:
             logger.error(f"Error selecting block: {e}", exc_info=True)
             return None
     
+    def _apply_block_selection_filtering(
+        self,
+        scored_blocks: List[tuple[ResponseBlock, float]],
+        topics: List[str],
+        normalized_text: str = ""
+    ) -> List[tuple[ResponseBlock, float]]:
+        """
+        Apply topic policy filtering at block selection time.
+        
+        When a high-priority topic is detected, restrict eligible blocks to allowed topics
+        and block denied topics unless explicitly mentioned.
+        """
+        if not topics:
+            return scored_blocks
+        
+        forced_topic = topics[0]  # First topic is the forced/high-priority one
+        policy = TopicEmotionDetector.TOPIC_POLICIES.get(forced_topic)
+        
+        if not policy:
+            # No policy for this topic, allow all blocks
+            return scored_blocks
+        
+        allowed_topics = policy.get('allow', set())
+        denied_topics = policy.get('deny', set())
+        text_lower = normalized_text.lower() if normalized_text else ""
+        
+        filtered_blocks = []
+        for block, score in scored_blocks:
+            block_topics = set(block.topics)
+            
+            # Check if block has any denied topics
+            has_denied = bool(block_topics & denied_topics)
+            if has_denied:
+                # Check explicit mention gates for denied topics
+                should_allow = False
+                for denied_topic in (block_topics & denied_topics):
+                    explicit_mentions = TopicEmotionDetector.EXPLICIT_MENTION_GATES.get(denied_topic, [])
+                    if any(mention in text_lower for mention in explicit_mentions):
+                        should_allow = True
+                        logger.info(f"[BlockFilter] Allowing block with denied topic '{denied_topic}' - explicit mention detected")
+                        break
+                
+                if not should_allow:
+                    logger.info(f"[BlockFilter] Filtered out block {block.id[:8]} - contains denied topics: {list(block_topics & denied_topics)}")
+                    continue
            
+            # Check if block has any allowed topics (if allowlist exists)
+            if allowed_topics:
+                has_allowed = bool(block_topics & allowed_topics)
+                if not has_allowed:
+                    logger.info(f"[BlockFilter] Filtered out block {block.id[:8]} - no allowed topics, has: {list(block_topics)}")
+                    continue
            
+            # Block passes filtering
+            filtered_blocks.append((block, score))
+        
+        if not filtered_blocks:
+            # Fallback: if filtering removed all blocks, return original (safety)
+            logger.warning(f"[BlockFilter] All blocks filtered out for forced_topic={forced_topic}, using original list")
+            return scored_blocks
+        
+        logger.info(f"[BlockFilter] Filtered {len(scored_blocks)} -> {len(filtered_blocks)} blocks for forced_topic={forced_topic}")
+        return filtered_blocks
+    
     def _weighted_random_choice(
         self,
         scored_blocks: List[tuple[ResponseBlock, float]],
@@ -920,6 +1039,7 @@ class AmoraBlocksService:
             # Detect topics and emotions
             context_topics = request.context.get('topics', []) if request.context else []
+            normalized_question = self.detector.normalize_text(question)
             topics = self.detector.detect_topics(question, context_topics)
             emotions = self.detector.detect_emotions(question, question_embedding)
             
             logger.info(f"[AmoraBlocks] User message: '{question[:100]}'")
+            logger.info(f"[AmoraBlocks] Normalized: '{normalized_question[:100]}'")
             logger.info(f"[AmoraBlocks] Detected topics: {topics}, emotions: {emotions}")
             
             # Determine stage for primary topic
             primary_topic = topics[0] if topics else 'general'
             
             # Select blocks - pass normalized text for block filtering
             if block_config['reflection'] > 0:
                 reflection = self.block_selector.select_block(
                     block_type='reflection',
                     question_embedding=question_embedding,
                     topics=topics,
                     emotions=emotions,
                     stage=stage,
                     recent_block_ids=state.recent_block_ids,
+                    normalized_text=normalized_question  # Pass for filtering
                 )
             
             if block_config['normalization'] > 0:
                 normalization = self.block_selector.select_block(
                     block_type='normalization',
                     question_embedding=question_embedding,
                     topics=topics,
                     emotions=emotions,
                     stage=stage,
                     recent_block_ids=state.recent_block_ids,
+                    normalized_text=normalized_question  # Pass for filtering
                 )
             
             if block_config['exploration'] > 0:
                 exploration = self.block_selector.select_block(
                     block_type='exploration',
                     question_embedding=question_embedding,
                     topics=topics,
                     emotions=emotions,
                     stage=stage,
                     recent_block_ids=state.recent_block_ids,
+                    normalized_text=normalized_question  # Pass for filtering
                 )
             
             if block_config['insight'] > 0 and stage >= 2:
                 reframe = self.block_selector.select_block(
                     block_type='reframe',
                     question_embedding=question_embedding,
                     topics=topics,
                     emotions=emotions,
                     stage=stage,
                     recent_block_ids=state.recent_block_ids,
+                    normalized_text=normalized_question  # Pass for filtering
                 )


diff --git a/backend/migrations/009_breakup_intimacy_blocks.sql b/backend/migrations/009_breakup_intimacy_blocks.sql
new file mode 100644
index 0000000..9dca6e0
--- /dev/null
+++ b/backend/migrations/009_breakup_intimacy_blocks.sql
@@ -0,0 +1,61 @@
+-- Migration: Add blocks for breakup_grief and breakup_intimacy_loss topics
+-- These blocks handle grief after breakups and missing physical intimacy/connection with an ex
+-- All blocks are non-explicit, ethical, and relationship-focused
+
+-- ============================================
+-- BREAKUP GRIEF BLOCKS (10-15 blocks)
+-- ============================================
+
+-- Reflection blocks for breakup grief
+INSERT INTO amora_response_blocks (block_type, text, topics, emotions, stage, priority, active) VALUES
+-- Stage 1-2 Reflection
+('reflection', 'It sounds like this breakup has left you feeling a deep sense of loss, and that grief is real and valid.', ARRAY['breakup_grief', 'heartbreak', 'breakup'], ARRAY['sad', 'hurt', 'lonely'], 1, 90, true),
+('reflection', 'I hear that you''re carrying a lot of pain right now, and the weight of this ending feels heavy.', ARRAY['breakup_grief', 'heartbreak', 'breakup'], ARRAY['sad', 'hurt', 'overwhelmed'], 1, 90, true),
+('reflection', 'It sounds like you''re grieving not just the person, but the future you imagined together, and that''s a profound kind of loss.', ARRAY['breakup_grief', 'heartbreak', 'breakup'], ARRAY['sad', 'hurt', 'lonely'], 2, 90, true),
+('reflection', 'I can hear how much this relationship meant to you, and how disorienting it feels to have it end.', ARRAY['breakup_grief', 'heartbreak', 'breakup'], ARRAY['sad', 'confused', 'hurt'], 1, 90, true),
+
+-- Stage 1-2 Normalization
+('normalization', 'Grief after a breakup isn''t linear—some days feel okay, others feel impossible, and that''s completely normal.', ARRAY['breakup_grief', 'heartbreak', 'breakup'], ARRAY['sad', 'hurt'], 1, 90, true),
+('normalization', 'It''s natural to wonder if you''ll ever feel okay again. Healing takes time, and there''s no "should" about how fast that happens.', ARRAY['breakup_grief', 'heartbreak', 'breakup'], ARRAY['sad', 'hopeless'], 1, 90, true),
+('normalization', 'Missing someone after a breakup, even when you know it''s over, is very common. Your feelings don''t have to make logical sense right now.', ARRAY['breakup_grief', 'heartbreak', 'breakup'], ARRAY['sad', 'lonely'], 2, 90, true),
+('normalization', 'Sometimes the hardest part isn''t the end itself, but learning who you are without them, and that process takes time.', ARRAY['breakup_grief', 'heartbreak', 'breakup'], ARRAY['sad', 'confused'], 2, 90, true),
+
+-- Stage 2 Insight (using 'reframe' block_type as insight blocks)
+('reframe', 'Grief often comes in waves—moments where you feel okay, followed by moments where the loss hits you all over again. This isn''t a sign that you''re not healing; it''s how grief works.', ARRAY['breakup_grief', 'heartbreak', 'breakup'], ARRAY['sad', 'hurt'], 2, 90, true),
+('reframe', 'When a relationship ends, you''re not just losing the person—you''re losing the routines, the inside jokes, the way you saw yourself through their eyes. That''s a lot to process.', ARRAY['breakup_grief', 'heartbreak', 'breakup'], ARRAY['sad', 'lonely'], 2, 90, true),
+
+-- Stage 1-2 Exploration
+('exploration', 'What part of this loss feels hardest to sit with right now?', ARRAY['breakup_grief', 'heartbreak', 'breakup'], ARRAY['sad', 'hurt'], 1, 90, true),
+('exploration', 'When you think about moving forward, what comes up for you?', ARRAY['breakup_grief', 'heartbreak', 'breakup'], ARRAY['sad', 'confused'], 1, 90, true),
+('exploration', 'What do you find yourself missing most—the person, or the feeling of being with them?', ARRAY['breakup_grief', 'heartbreak', 'breakup'], ARRAY['sad', 'lonely'], 2, 90, true),
+('exploration', 'Looking back, what needs of yours weren''t being met in that relationship?', ARRAY['breakup_grief', 'heartbreak', 'breakup'], ARRAY['sad', 'hurt'], 2, 90, true);
+
+-- ============================================
+-- BREAKUP INTIMACY LOSS BLOCKS (10-15 blocks)
+-- ============================================
+
+-- Reflection blocks for missing intimacy with ex
+INSERT INTO amora_response_blocks (block_type, text, topics, emotions, stage, priority, active) VALUES
+-- Stage 1-2 Reflection
+('reflection', 'It sounds like you''re missing the physical closeness and connection you had with your ex, and that''s a real part of what you''re grieving.', ARRAY['breakup_intimacy_loss', 'breakup_grief', 'heartbreak'], ARRAY['sad', 'lonely', 'hurt'], 1, 95, true),
+('reflection', 'I hear that you miss the way you and your ex connected physically, and that loss feels significant to you.', ARRAY['breakup_intimacy_loss', 'breakup_grief', 'heartbreak'], ARRAY['sad', 'lonely'], 1, 95, true),
+('reflection', 'It sounds like the physical intimacy you shared was an important part of what made that relationship feel special, and missing that is natural.', ARRAY['breakup_intimacy_loss', 'breakup_grief', 'heartbreak'], ARRAY['sad', 'hurt'], 2, 95, true),
+('reflection', 'I can hear how much you miss the closeness and chemistry you had together, and that''s a real part of what you''re processing right now.', ARRAY['breakup_intimacy_loss', 'breakup_grief', 'heartbreak'], ARRAY['sad', 'lonely'], 1, 95, true),
+
+-- Stage 1-2 Normalization
+('normalization', 'Missing the physical connection you had with an ex is very common, especially when that was a meaningful part of your relationship.', ARRAY['breakup_intimacy_loss', 'breakup_grief', 'heartbreak'], ARRAY['sad', 'lonely'], 1, 95, true),
+('normalization', 'It''s natural to grieve the loss of physical intimacy along with the emotional connection. Both were part of what made that relationship what it was.', ARRAY['breakup_intimacy_loss', 'breakup_grief', 'heartbreak'], ARRAY['sad', 'hurt'], 1, 95, true),
+('normalization', 'Physical intimacy often represents safety, closeness, and being seen in a particular way. Missing that doesn''t mean you''re just missing sex—it''s often about missing that sense of connection.', ARRAY['breakup_intimacy_loss', 'breakup_grief', 'heartbreak'], ARRAY['sad', 'lonely'], 2, 95, true),
+('normalization', 'The way you connected physically with your ex was unique to that relationship, and it makes sense that you''d miss that specific kind of closeness.', ARRAY['breakup_intimacy_loss', 'breakup_grief', 'heartbreak'], ARRAY['sad', 'hurt'], 2, 95, true),
+
+-- Stage 2 Insight (using 'reframe' block_type as insight blocks)
+('reframe', 'Physical intimacy in a relationship often represents more than just physical connection—it can be about feeling desired, safe, understood, or fully yourself with someone. Missing that can feel like missing a whole dimension of how you related to each other.', ARRAY['breakup_intimacy_loss', 'breakup_grief', 'heartbreak'], ARRAY['sad', 'lonely'], 2, 95, true),
+('reframe', 'Sometimes what we miss most about physical intimacy with an ex isn''t just the act itself, but the way it made us feel—seen, wanted, connected, or at ease. That emotional layer is part of what you''re grieving.', ARRAY['breakup_intimacy_loss', 'breakup_grief', 'heartbreak'], ARRAY['sad', 'hurt'], 2, 95, true),
+
+-- Stage 1-2 Exploration
+('exploration', 'What was it about the physical connection you had that feels hardest to let go of?', ARRAY['breakup_intimacy_loss', 'breakup_grief', 'heartbreak'], ARRAY['sad', 'lonely'], 1, 95, true),
+('exploration', 'When you think about missing that intimacy, what comes up for you—is it more about the physical closeness, or what it represented in your relationship?', ARRAY['breakup_intimacy_loss', 'breakup_grief', 'heartbreak'], ARRAY['sad', 'hurt'], 1, 95, true),
+('exploration', 'What did that physical connection give you that feels missing now?', ARRAY['breakup_intimacy_loss', 'breakup_grief', 'heartbreak'], ARRAY['sad', 'lonely'], 2, 95, true),
+('exploration', 'How does missing that intimacy connect to other parts of what you''re grieving about the relationship?', ARRAY['breakup_intimacy_loss', 'breakup_grief', 'heartbreak'], ARRAY['sad', 'hurt'], 2, 95, true);

diff --git a/backend/tests/test_topic_detection.py b/backend/tests/test_topic_detection.py
new file mode 100644
index 0000000..a1b2c3d
--- /dev/null
+++ b/backend/tests/test_topic_detection.py
@@ -0,0 +1,79 @@
+"""
+Test suite for topic detection improvements.
+Tests that breakup grief and breakup intimacy loss are correctly detected.
+"""
+import pytest
+from app.services.amora_blocks_service import TopicEmotionDetector
+
+
+class TestTopicDetection:
+    """Test topic detection with normalization and priority routing."""
+    
+    def test_heartbreak_detection(self):
+        """Test that 'Im heartbroken' detects breakup_grief/heartbreak."""
+        topics = TopicEmotionDetector.detect_topics("Im heartbroken")
+        assert 'heartbreak' in topics or 'breakup_grief' in topics
+        assert topics != ['general']
+        assert topics[0] in ['breakup_grief', 'heartbreak']  # High-priority first
+    
+    def test_missing_ex_detection(self):
+        """Test that 'I miss my ex' detects breakup_grief."""
+        topics = TopicEmotionDetector.detect_topics("I miss my ex")
+        assert 'breakup' in topics or 'breakup_grief' in topics or 'heartbreak' in topics
+        assert topics != ['general']
+    
+    def test_missing_sex_life_with_ex_detection(self):
+        """Test that 'I miss our sex life with my ex' detects breakup_intimacy_loss (dual-signal)."""
+        topics = TopicEmotionDetector.detect_topics("I miss our sex life with my ex")
+        assert 'breakup_intimacy_loss' in topics
+        assert topics[0] == 'breakup_intimacy_loss'  # High-priority first
+        assert topics != ['general']
+    
+    def test_missing_sex_life_without_ex(self):
+        """Test that 'I miss our sex life' does NOT detect breakup_intimacy_loss (no breakup signal)."""
+        topics = TopicEmotionDetector.detect_topics("I miss our sex life")
+        assert 'breakup_intimacy_loss' not in topics  # Requires both signals
+    
+    def test_missing_way_we_had_sex_detection(self):
+        """Test that 'i miss the way i and my ex do have sex' detects breakup_intimacy_loss."""
+        topics = TopicEmotionDetector.detect_topics("i miss the way i and my ex do have sex")
+        assert 'breakup_intimacy_loss' in topics
+        assert topics[0] == 'breakup_intimacy_loss'  # High-priority first
+        assert topics != ['general']
+    
+    def test_missing_sex_with_explicit_unlovable(self):
+        """Test that 'I miss our sex with my ex and I feel unlovable' keeps both topics."""
+        topics = TopicEmotionDetector.detect_topics("I miss our sex with my ex and I feel unlovable")
+        assert 'breakup_intimacy_loss' in topics
+        assert 'unlovable' in topics  # Should keep it because explicitly stated
+        assert topics[0] == 'breakup_intimacy_loss'  # High-priority first
+    
+    def test_missing_sex_without_unlovable(self):
+        """Test that 'I miss our sex life with my ex' does NOT detect unlovable."""
+        topics = TopicEmotionDetector.detect_topics("I miss our sex life with my ex")
+        assert 'breakup_intimacy_loss' in topics
+        assert 'unlovable' not in topics  # Should NOT have unlovable
+        assert topics[0] == 'breakup_intimacy_loss'  # High-priority first
+    
+    def test_text_normalization(self):
+        """Test that text normalization handles contractions and typos."""
+        normalized = TopicEmotionDetector.normalize_text("Im heartbroken and I dont know what to do")
+        assert "i am" in normalized or "im" not in normalized.lower()
+        assert "do not" in normalized or "dont" not in normalized.lower()
+    
+    def test_contractions_handling(self):
+        """Test that 'Im' is normalized to 'i am' for better matching."""
+        topics1 = TopicEmotionDetector.detect_topics("Im heartbroken")
+        topics2 = TopicEmotionDetector.detect_topics("I am heartbroken")
+        # Both should detect heartbreak
+        assert (('heartbreak' in topics1 or 'breakup_grief' in topics1) and
+                ('heartbreak' in topics2 or 'breakup_grief' in topics2))
+        # Both should have same first topic (deterministic)
+        assert topics1[0] == topics2[0]
+    
+    def test_priority_routing(self):
+        """Test that breakup_intimacy_loss has priority over generic topics."""
+        topics = TopicEmotionDetector.detect_topics("i miss the way me and my ex do have sex")
+        assert 'breakup_intimacy_loss' in topics
+        assert topics[0] == 'breakup_intimacy_loss'  # High-priority first
+        # Should NOT have unrelated topics
+        assert 'lust_vs_love' not in topics
+    
+    def test_breakup_context_removes_unlovable(self):
+        """Test that breakup context removes unlovable unless explicitly stated."""
+        topics = TopicEmotionDetector.detect_topics("Im heartbroken and everything feels wrong")
+        assert 'heartbreak' in topics or 'breakup_grief' in topics
+        # Should NOT have unlovable unless explicitly stated
+        assert 'unlovable' not in topics
+    
+    def test_deterministic_ordering(self):
+        """Test that topic ordering is deterministic (high-priority first)."""
+        topics1 = TopicEmotionDetector.detect_topics("Im heartbroken and I miss our sex life with my ex")
+        topics2 = TopicEmotionDetector.detect_topics("Im heartbroken and I miss our sex life with my ex")
+        # Should return same order
+        assert topics1 == topics2
+        # First topic should be high-priority
+        assert topics1[0] in ['breakup_intimacy_loss', 'breakup_grief']
